#!/bin/bash

#'
#' Script to create files for baypass.
#'
#' Before running this on the cluster, combine the necessary sample info
#' files into a tar file:
#'
#' cd THIS_REPO \
#'     && cd _data \
#'     && export SAMP_DIR=tany-sample-info \
#'     && mkdir ${SAMP_DIR} \
#'     && cp full-sample-info.csv tany-abundances.csv ./${SAMP_DIR}/ \
#'     && tar -cz --no-xattrs --exclude ".*" -f ${SAMP_DIR}.tar.gz ${SAMP_DIR} \
#'     && scp ${SAMP_DIR}.tar.gz lnell@transfer.chtc.wisc.edu:/staging/lnell/
#'

. /app/.bashrc
conda activate baypass-env

export THREADS=$(count_threads)

# Edit these for your system:
export DATA_TAR_FULL_PATH="/staging/lnell/tany-sample-info.tar.gz"
export SAMPLE_INFO="full-sample-info.csv"
export ABUNDANCES="tany-abundances.csv"
export COUNTS_TAR_FULL_PATH="/staging/lnell/dna/snape/count_masked_time.tar"
export COUNTS_IN="count_masked_time_noblanks.sync.gz"
export NAMES_IN="count_masked_time.names.gz"
export PARENT_DIR_OUT="/staging/lnell/dna/baypass"






#' ========================================================================
#' Inputs
#' ========================================================================


if [ ! -f ${DATA_TAR_FULL_PATH} ]; then
    echo "${DATA_TAR_FULL_PATH} does not exist! " 1>&2
    safe_exit 111
fi
if [ ! -f ${COUNTS_TAR_FULL_PATH} ]; then
    echo "${COUNTS_TAR_FULL_PATH} does not exist! " 1>&2
    safe_exit 222
fi


export OUT_DIR="baypass-inputs"
# For sample info files:
export SAMPLE_FILE_PREFIX="tany"


mkdir ${OUT_DIR}
cd ${OUT_DIR}


# Files containing sample and abundance info:
tar -xzf ${DATA_TAR_FULL_PATH} -C ./
check_exit_status "cp, extract sample info tar" $?
cd $(basename ${DATA_TAR_FULL_PATH%.tar.gz})
mv ${SAMPLE_INFO} ${ABUNDANCES} ../
cd ..
rm -r $(basename ${DATA_TAR_FULL_PATH%.tar.gz})


# Files containing counts and info:
tar -xf ${COUNTS_TAR_FULL_PATH} -C ./
check_exit_status "cp, extract counts tar" $?
cd $(basename ${COUNTS_TAR_FULL_PATH%.tar})
mv ${COUNTS_IN} ${NAMES_IN} ../
cd ..
rm -r $(basename ${COUNTS_TAR_FULL_PATH%.tar})



#' ========================================================================
#' Write baypass input files
#' ========================================================================


Rscript --vanilla - << EOF

suppressPackageStartupMessages({
    library(tidyverse)
    library(poolfstat)
})

.n_threads <- ${THREADS}
in_files <- list(samp_info = "${SAMPLE_INFO}",
                 names = "${NAMES_IN}",
                 counts = "${COUNTS_IN}",
                 abunds = "${ABUNDANCES}")
out_prefix <- "${SAMPLE_FILE_PREFIX}"

samp_df <- read_csv(in_files[["samp_info"]], col_types = "cDccidd")

pools <- read_lines(in_files[["names"]])
n_haps <- pools |>
    set_names() |>
    map_int(\(x) 2L * samp_df[["n_adults"]][samp_df[["biotech_id"]] == x]) |>
    as.list()

cat("Reading pool data...\n")
#' Remove very low coverage and non-biallelic SNPs, read into pooldata object.
pool_dat <- popsync2pooldata(sync.file = in_files[["counts"]],
                             poolsizes = n_haps,
                             poolnames = pools,
                             nthreads = .n_threads)

#' Remove SNPs near fixation because
#' "... nearly fixed markers (e.g., π < 0.05 or π > 0.95) are not expected to be
#' associated with any covariate, even if they are adjacent to strongly
#' associated SNPs, which can severely degrade the detection of clustered
#' signals." (BayPass v1.31 manual)
#'
cat("Filtering pool data...\n")
# Create a logical vector for which SNPs aren't near fixation:
avg_ref_probs <- apply(pool_dat@refallele.readcount / pool_dat@readcoverage,
                       1, mean)
poly_snps <- avg_ref_probs > 0.1 & avg_ref_probs < 0.9
# Now updating fields:
pool_dat@nsnp <- sum(poly_snps)
pool_dat@refallele.readcount <- pool_dat@refallele.readcount[poly_snps,]
pool_dat@readcoverage <- pool_dat@readcoverage[poly_snps,]
pool_dat@snp.info <- pool_dat@snp.info[poly_snps,]


#' Now convert to format for baypass.
#' I use 'subsamplesize = pool_dat@nsnp %/% 5L' below to generate 5
#' pseudo-independent datasets.
#' This is because baypass doesn't scale linearly with number of
#' threads, so including more threads doesn't help with larger datasets
#' (> 8 isn't generally worthwhile).
#' Using multiple datasets is more efficient.
#' Also, this:
#' > the sub-sampling approach allows comparing results across
#' > (pseudo-independent) sub-sets, each of which additionally has a lower
#' > level of background LD (if a thinning approach has been performed
#' > to generate the sub-sets).
#' (BayPass v2.31 manual)

cat("Writing pool data...\n")
pooldata2genobaypass(pool_dat, prefix = out_prefix,
                     subsamplesize = pool_dat@nsnp %/% 5L)
# 5 sub-samples of ca. 86672 SNPs will be generated by tacking one SNP every 5


#' Lastly, write a file for the covariate, log(density + 1):
cat("Writing covariate data...\n")
pop_df <- read_csv(in_files[["abunds"]], col_types = "ifdd") |>
    mutate(gen = as.integer(gen))
pools |>
    str_remove_all("^SN-|_S.?.?\$") |>
    str_split("-") |>
    map(as.integer) |>
    set_names(pools) |>
    imap(\(x, p) {
        yr <- ifelse(x[2] < 77, 2000L + x[2], 1900L + x[2])
        gen <- x[1]
        lgl <- pop_df[["gen"]] == gen & pop_df[["year"]] == yr
        tibble(pool = p, logN = pop_df[["logN"]][lgl])
    }) |>
    list_rbind() |>
    # Make it the same order as 'pools':
    arrange(match(pool, pools)) |>
    # Now extract just 'logN' and write to file:
    getElement("logN") |>
    round(4) |>
    paste(collapse = " ") |>
    write_lines(file = paste0(out_prefix, "-log_n.txt"))

EOF




#' ========================================================================
#' Deal with outputs
#' ========================================================================


cd ..
tar -czf ${OUT_DIR}.tar.gz ${OUT_DIR}

cp ${OUT_DIR}.tar.gz ${PARENT_DIR_OUT}/

rm -r ${OUT_DIR}


exit 0


# count_masked_time.names.gz
# count_masked_time_noblanks.sync.gz
# full-sample-info.csv
# tany-abundances.csv
# tany.genobaypass.sub1
# tany.genobaypass.sub2
# tany.genobaypass.sub3
# tany.genobaypass.sub4
# tany.genobaypass.sub5
# tany-log_n.txt
# tany.poolsize
# tany.snpdet.sub1
# tany.snpdet.sub2
# tany.snpdet.sub3
# tany.snpdet.sub4
# tany.snpdet.sub5
